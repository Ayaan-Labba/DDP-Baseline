{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8fe26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayaan-ubuntu/.pyenv/versions/glirel-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from glirel import GLiREL\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d61b844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayaan-ubuntu/.pyenv/versions/glirel-env/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = GLiREL.from_pretrained(\"jackboyla/glirel-large-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "816b7db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f1f69b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Derren Nesbitt had a history of being cast in \"Doctor Who\", having played villainous warlord Tegana in the 1964 First Doctor serial \"Marco Polo\".'\n",
    "doc = nlp(text)\n",
    "tokens = [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "011f4ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['acted in', 'played as', 'father of', 'character played by', 'year of']\n",
    "\n",
    "ner = [[0, 1, 'PERSON', 'Derren Nesbitt'], [10, 11, 'ORG', 'Doctor Who']] # 'type' is not used -- it can be any string!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65c6b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = model.predict_relations(tokens, labels, threshold=0.0, ner=ner, top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66d709bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relations: 2\n"
     ]
    }
   ],
   "source": [
    "print('Number of relations:', len(relations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10b2392c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descending Order by Score:\n",
      "['Derren', 'Nesbitt'] --> acted in --> ['Doctor', 'Who'] | score: 0.6717198491096497\n",
      "['Doctor', 'Who'] --> acted in --> ['Derren', 'Nesbitt'] | score: 0.545129656791687\n"
     ]
    }
   ],
   "source": [
    "sorted_data_desc = sorted(relations, key=lambda x: x['score'], reverse=True)\n",
    "print(\"\\nDescending Order by Score:\")\n",
    "for item in sorted_data_desc:\n",
    "    print(f\"{item['head_text']} --> {item['label']} --> {item['tail_text']} | score: {item['score']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glirel-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
